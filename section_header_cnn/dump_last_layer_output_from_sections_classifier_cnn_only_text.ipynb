{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to dump layer output for ontology. We will dump encoded layer an also last last. This sentecne level \n",
    "embedding matrix will be used for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import keras\n",
    "from tensorflow.contrib.keras import models\n",
    "from tensorflow.contrib.keras import datasets\n",
    "from tensorflow.contrib.keras import layers\n",
    "from tensorflow.contrib.keras import preprocessing\n",
    "from tensorflow.contrib.keras import backend as K\n",
    "from tensorflow.contrib.keras import callbacks\n",
    "from tensorflow.contrib.keras import utils\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.85\n",
    "#config.gpu_options.allow_growth=True\n",
    "config.gpu_options.visible_device_list=\"0\"\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.set_session(session)\n",
    "K.gpu_setup = [\"gpu0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir=\"cnn_only_text_sections_classifiers_3_classes/\"\n",
    "model_path=model_dir+\"weights-improvement-11-0.858519382.hdf5\"\n",
    "x_train_title_path= model_dir+\"x_train_char\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load model from dump\n",
    "ld_model= models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load x_train title data data\n",
    "#x_train_title = np.load(x_train_title_path, mmap_mode='r')\n",
    "x_train_char = pickle.load(open(model_dir+\"x_train_char\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see the layers name\n",
    "for ly in ld_model.layers:\n",
    "    print ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the tensor for the last fully connected layer \n",
    "last_fully_conn_layer_output_variable = K.function([ld_model.layers[0].input\n",
    "                                        ,K.learning_phase()],[ld_model.layers[5].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open(model_dir+'cnn_embedding_four_class_only_text_layer.dat','a')\n",
    "batch_size=100\n",
    "n_split=int(math.ceil(len(x_train_char)/float(batch_size)))\n",
    "for i in range(n_split):\n",
    "    #print \"Processing chunk:\",i+1\n",
    "    layer_output = last_fully_conn_layer_output_variable([x_train_char[i*batch_size:(i+1)*batch_size], 0]) \n",
    "    #np.save(output,layer_6th_output[0])\n",
    "#     for j in range(len(layer_output[0])):\n",
    "#         np.savetxt(output,[layer_output[0][j].ravel()],fmt='%f')\n",
    "    np.savetxt(output,layer_output[0],fmt='%f')\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_emb = np.loadtxt(model_dir+'cnn_embedding_four_class_only_text_layer.dat',\n",
    "                    dtype ='float32',delimiter = ' ')\n",
    "np.save(model_dir+'cnn_embedding_four_class_only_text_layer.npy',df_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
